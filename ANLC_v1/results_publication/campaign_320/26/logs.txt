Run of the control_2DOF_inv_pend_ANLC_campaign system.
Convergence reached = True

TRAINING PARAMS: 
Seed = 27
max_loop_number = 1
max_epochs_per_loop = 1000
Initial dataset dimension = 500
Final dataset dimension = 800
Using a sliding window = True
Maximum dataset dimension (if using sliding wind) = 800
Re-initialise dataset = False


LYAPUNOV ANN: 
layer 1 dim. = 10
layer 1 act. f. = linear
layer 1 has bias = False
layer 2 dim. = 10
layer 2 has act. f. = pow2
layer 2 has bias = False
layer 3 dim. = 1
layer 3 has act. f. = linear
layer 3 has bias = False


CONTROL ANN: 
Use linear control = True
If nonlinear control law is used, then:
dim. layer 1 = 2
dim layer 2 = 2
use bias layer 1 = False
use bias layer 2 = False


LEARNER: 
Learning rate Lyap. = 0.01
Learning rate control = 1.0

LYAPUNOV RISK:
alpha_1 (Weight V) = 1.0
alpha_2 (Weight V_dot) = 1.0
alpha_3 (Weight V0) = 1.0
alpha_4 (Weight V tuning) = 0.0
alpha_5(overall weight) = 1.0
alpha_roa (ROA tuning) = 6.0


TRAINING: 
ANN control initialised (LQR) = False
ANN control initial weights = tensor([[-23.5864,  -5.3142]])
ANN control final weights = tensor([[-3.4137, -1.0692]])


FALSIFIER (SMT): 
Epsilon = 0.0
Falsifier domain = 0.1 - 6.0
config.precision = 1e-06
mu (falsifier callback interval) = 50
zeta_SMT (SMT CE point cloud) = 200

DISCRETE FALSIFIER (DF): 
zeta_D (DF CEs added at each callback) = 300
use adaptive grid = True
maximum grid points = 1000
Final grid points = 500


RESULTS: 
Falsifier Time Out = False
Learner Time Out = False
Time elapsed: 
seconds = 32.71705302500004
minutes = 0.545284217083334
hours = 0.009088070284722232
Falsifier time [']: 0.3805702469333331
Falsifier time [%]: 69.79300610770692
Training iterations completed = 1
Training epochs (last iteration) = 72


